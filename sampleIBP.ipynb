{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian Buffet Process Prior\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indian Buffet Process Function\n",
    "\n",
    "def sampleIBP(alpha, num_objects):\n",
    "    \n",
    "    # Initializing storage for results\n",
    "    result = np.zeros([num_objects, 1000])\n",
    "    # Draw from the prior for alpha\n",
    "    t = np.random.poisson(alpha)\n",
    "    # Filling in first row of result matrix\n",
    "    result[0, 0:t] = np.ones([1, t])\n",
    "    # Initializing K+\n",
    "    K_plus = t\n",
    "    \n",
    "\n",
    "    for i in range(1, num_objects):\n",
    "        for j in range(0, K_plus):\n",
    "            p = np.array([np.log(np.sum(result[0:i,j])) - np.log(i), \n",
    "                          np.log(i - np.sum(result[0:i, j])) - np.log(i)])\n",
    "            p = np.exp(p - max(p))\n",
    "\n",
    "            if(np.random.uniform() < p[0]/np.sum(p)):\n",
    "                result[i, j] = 1\n",
    "            else:\n",
    "                result[i, j] = 0\n",
    "        t = np.random.poisson(alpha/i)\n",
    "        x = K_plus + 1\n",
    "        y = K_plus + t\n",
    "        result[i, (x-1):y] = np.ones([1, t]) # NEED TO CHECK DIM\n",
    "        K_plus = K_plus+t\n",
    "    result = result[:, 0:K_plus]\n",
    "    return list([result, K_plus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,\n",
       "          0.],\n",
       "        [ 1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.],\n",
       "        [ 1.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,\n",
       "          1.]]), 14]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleIBP(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Simplification\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for enhancing inverse process\n",
    "\n",
    "def calcInverse(Z, M, i, k, val):\n",
    "    M_i = M - (np.dot(np.dot(np.dot(M, Z[i,:].T), Z[i,:]), M)) / (np.dot(np.dot(Z[i,:], M), Z[i,:].T) - 1)\n",
    "    Z[i, k] = val\n",
    "    M = M_i - (np.dot(np.dot(np.dot(M_i, Z[i,:].T), Z[i,:]), M_i)) / (np.dot(np.dot(Z[i,:], M_i), Z[i,:].T) + 1)\n",
    "    Inv = M\n",
    "    return(Inv)\n",
    "\n",
    "def calcInverse1(Z, M, i, k, val):\n",
    "    # Calculating M_i\n",
    "    part1 = M\n",
    "    part2 = np.dot(M, Z[i,:].T)\n",
    "    part3 = np.dot(part2, Z[i,:])\n",
    "    part4 = np.dot(part3, M)\n",
    "    part5 = np.dot(Z[i,:], M)\n",
    "    part6 = np.dot(part5, Z[i,:].T) - 1\n",
    "\n",
    "    M_i = part1 - part4 / part6\n",
    "\n",
    "    Z[i, k] = val\n",
    "\n",
    "    #Calculating M\n",
    "    part1 = M_i\n",
    "    part2 = np.dot(M_i, Z[i,:].T)\n",
    "    part3 = np.dot(part2, Z[i,:])\n",
    "    part4 = np.dot(part3, M_i)\n",
    "    part5 = np.dot(Z[i,:], M_i)\n",
    "    part6 = np.dot(part5, Z[i,:].T) + 1\n",
    "\n",
    "    M = part1 - part4 / part6\n",
    "\n",
    "    Inv = M\n",
    "    return(Inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calcInverse(Z[:, 0:K_plus], M, i, k, 1)\n",
    "print(\"K_plus = \", K_plus)\n",
    "print(\"Z[:, 0:K_plus] = \", Z[:, 0:K_plus])\n",
    "print(\"M = \", M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood Function \n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define the likelihood function ##\n",
    "# The function returns the log likelihood\n",
    "def likelihood(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    part1 = - (num_objects*(object_dim/2)*np.log(2*np.pi))\n",
    "    part2 = - (num_objects-K_plus)* object_dim *np.log(sigma_X) \n",
    "    part3 = - (object_dim*K_plus)*np.log(sigma_A) \n",
    "    part4 = - (object_dim/2)* np.log(np.dot(np.transpose(Z),Z) + (sigma_X/sigma_A)**2 * np.identity(K_plus))\n",
    "    part5 = (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(np.transpose(X),(np.identity(num_objects) - np.dot(np.dot(Z,M),np.transpose(Z)))),X))\n",
    "    total = part1+part2+part3+part4+part5\n",
    "    return(total)\n",
    "\n",
    "def likelihood1(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    log_ll = -1 * num_objects * object_dim * .5 * np.log(2*np.pi) - 1 * (num_objects - K_plus) * object_dim * np.log(sigma_X) - K_plus * object_dim * np.log(sigma_A) - object_dim * .5 * np.log(np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))) + (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(X.T, np.eye(num_objects) - np.dot(Z, np.dot(M, Z.T))), X))\n",
    "    return(log_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "O = np.array([[2,2], [1,1]])\n",
    "np.linalg.det(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Generation\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvtnorm\n",
    "from scipy.stats import bernoulli\n",
    "import numpy as np\n",
    "\n",
    "### Data Simulation ###\n",
    "\n",
    "## Features/Latent Variables #\n",
    "#Each row of the weight matrix \"W\" specifies one base images(feature/latent variables)\"\n",
    "\n",
    "W = np.array([[0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]])\n",
    "\n",
    "\n",
    "#Each image in our simulated data set is the superposition of four base images#\n",
    "# Number of images/ data points\n",
    "num_objects=100\n",
    "\n",
    "#Dimension of image (6x6)\n",
    "object_dim  = 6*6\n",
    "\n",
    "#Covariance matrix for images/ white noise\n",
    "sigma_x_orig = 0.5\n",
    "I = sigma_x_orig * np.identity(object_dim)\n",
    "\n",
    "#z_i - binary feature matrix (1 x 4) - each entry set to 1 with probability 0.5 and 0 otherwise#\n",
    "#x is data variable - each row correspondes to a superimposed built from a random combination of latent features#\n",
    "#with white noise added - x is built with multivariate gaussian#\n",
    "x = np.zeros((100,36))\n",
    "z = np.zeros((100,4))\n",
    "\n",
    "for i in range(0,num_objects):\n",
    "    z[i,:] = np.array([bernoulli.rvs(p=0.5, size=4)])\n",
    "    x[i,:] = mvtnorm.rvs(np.dot(z[i,:],W), I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sampler\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,4) (5,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-361b326c063e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_plus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msigma_X\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msigma_A\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# MINUS ONE TO FIX DIMENSIONALITY MAY BE INCORRECT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,4) (5,5) "
     ]
    }
   ],
   "source": [
    "# GENERAL FUNCTION SAMPLER\n",
    "\n",
    "# Harmonic number or N\n",
    "HN = 0\n",
    "for i in range(0, num_objects):\n",
    "    HN = HN + 1/(i+1)\n",
    "\n",
    "E = 1000\n",
    "BURN_IN = 0\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "# Initializing values for use in our chain\n",
    "sigma_A = 1\n",
    "sigma_X = 1\n",
    "# Poisson rate\n",
    "alpha = 1\n",
    "# Prespecified maximum number of latent features\n",
    "K_inf = 10\n",
    "# Indian Buffet Process Prior\n",
    "Z, K_plus = sampleIBP(alpha, num_objects)\n",
    "# Initialization of our chain for Z\n",
    "chain_Z = np.zeros([SAMPLE_SIZE, num_objects, K_inf])\n",
    "# Initialization of our chain for K\n",
    "chain_K = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for sigma_X\n",
    "chain_sigma_X = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for sigma_A\n",
    "chain_sigma_A = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for alpha\n",
    "chain_alpha = np.zeros([SAMPLE_SIZE, 1])\n",
    "\n",
    "# Initializing storage for post burn-in samples\n",
    "s_counter = 0\n",
    "for e in range(0, E):\n",
    "    if(e > BURN_IN):\n",
    "        s_counter = s_counter + 1\n",
    "        chain_Z[s_counter, :, 0:K_plus] = Z[:, 0:K_plus]\n",
    "        chain_K[s_counter] = K_plus\n",
    "        chain_sigma_X[s_counter] = sigma_X\n",
    "        chain_sigma_A[s_counter] = sigma_A\n",
    "        chain_alpha[s_counter] = alpha\n",
    "    #print(\"At iteration\", e, \": K_plus is\", K_plus, \", alpha is\", alpha) \n",
    "\n",
    "    for i in range(0, num_objects):\n",
    "        # M matrix will be handy for future computations\n",
    "        # SOMETIMES SINGULAR, NEED TO FIX\n",
    "        M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "        for k in range(0, K_plus):\n",
    "            # Checking to make sure that k < K_plus\n",
    "            if k >= K_plus:\n",
    "                break\n",
    "            if Z[i, k] > 0:\n",
    "                # Take care of singularities\n",
    "                if np.sum(Z[:, k]) - Z[i, k] <= 0:\n",
    "                    Z[i, k] = 0\n",
    "                    Z[:, k:(K_plus - 1)] = Z[:, (k+1):K_plus]\n",
    "                    K_plus = K_plus - 1\n",
    "                    M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "                    continue\n",
    "             \n",
    "            # This is where he has his calcInverse functions to \n",
    "            # speed up inverse calculations. I just use inverse\n",
    "            # of Z matrix below\n",
    "            M1 = calcInverse(Z[:, 0:K_plus], M, i, k, 1)\n",
    "            M2 = calcInverse(Z[:, 0:K_plus], M, i, k, 0)\n",
    "\n",
    "            # Compute conditional distributions for the current cell in Z\n",
    "            P = []\n",
    "            Z[i, k] = 1\n",
    "            P.append(likelihood1(x, Z[:, 0:K_plus], M1, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(sum(Z[:, k]) - Z[i, k]) - np.log(num_objects))\n",
    "\n",
    "            Z[i, k] = 0\n",
    "            P.append(likelihood1(x, Z[:, 0:K_plus], M2, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(num_objects - sum(Z[:,k])) - np.log(num_objects))\n",
    "            \n",
    "            P = np.exp(P - np.max(P))\n",
    "\n",
    "            # Sample from the conditional\n",
    "            if np.random.uniform() < P[0] / (P[0] + P[1]):\n",
    "                Z[i, k] = 1\n",
    "                M = M1\n",
    "            else:\n",
    "                Z[i, k] = 0\n",
    "                M = M2\n",
    "        \n",
    "        # Sample the number of new dishes for the current object\n",
    "        trun = np.zeros([1, 5])\n",
    "        alpha_N = alpha / num_objects\n",
    "\n",
    "\n",
    "################### ERROR IN DIMENSIONALITY RIGHT HERE ###########################        \n",
    "        for k_i in range(0, 5):\n",
    "            Z[i, K_plus:(K_plus+k_i)] = 1\n",
    "            M = np.linalg.inv(np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i)) # MINUS ONE TO FIX DIMENSIONALITY MAY BE INCORRECT\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.linalg.inv(np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i))\n",
    "#np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i-1)\n",
    "k_i\n",
    "i\n",
    "Z[i, K_plus:(K_plus+k_i)] = 1\n",
    "Z[i, K_plus:(K_plus+k_i)]\n",
    "K_plus\n",
    "Z[i, :]\n",
    "Z[:, 0:(K_plus + k_i)]\n",
    "k_i \n",
    "Z.shape\n",
    "K_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,4) (5,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-b8943869237e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m             \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_plus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m             \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msigma_X\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msigma_A\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,4) (5,5) "
     ]
    }
   ],
   "source": [
    "for k_i in range(0, 5):\n",
    "            Z[i, K_plus:(K_plus+k_i)] = 1\n",
    "            M = np.linalg.inv(np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
