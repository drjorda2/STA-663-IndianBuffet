{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 14,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Uploading required packages\n",
    "import numpy as np\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import uniform as unif\n",
    "from scipy.stats import multivariate_normal as mvtnorm\n",
    "from scipy.stats import bernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating the Data\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are four 6x6 base images, which are the latent variables. \n",
    "\n",
    "The latent variables can be represented by a $K * D $ matrix of weights, where $K=4 $ and $D=36 $ "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 43,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each row of the weight matrix \"W\" specifies one base images(feature/latent variables)\"\n",
    "\n",
    "W = np.array([[0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the four latent images"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 36,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAABlCAYAAACRByIyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
<<<<<<< HEAD
       "[array([[ 1.]]), 1]"
      ]
     },
     "execution_count": 19,
=======
       "<matplotlib.figure.Figure at 0x10cc70d68>"
      ]
     },
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "a=fig.add_subplot(1,4,1)\n",
    "plt.imshow(np.matrix(W[0]).reshape(6,6),cmap=plt.get_cmap('gray'),  interpolation='nearest',origin='lower')\n",
    "a=fig.add_subplot(1,4,2)\n",
    "plt.imshow(np.matrix(W[1]).reshape(6,6),cmap=plt.get_cmap('gray'),  interpolation='nearest',origin='lower')\n",
    "a=fig.add_subplot(1,4,3)\n",
    "plt.imshow(np.matrix(W[2]).reshape(6,6),cmap=plt.get_cmap('gray'),  interpolation='nearest',origin='lower')\n",
    "a=fig.add_subplot(1,4,4)\n",
    "plt.imshow(np.matrix(W[3]).reshape(6,6),cmap=plt.get_cmap('gray'),  interpolation='nearest',origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulated 100 6 x 6 images, such that each image is combination of one more latent images with added noise\n",
    "\n",
    "$x_i \\sim Normal(z_i W, \\Sigma_X = \\sigma_x I)$\n",
    "\n",
    "$z_i \\sim binomial(n=4, p=0.5)$\n",
    "\n",
    "X can be represented by a $N * D$ where $N=100$ and $D=36$\n",
    "\n",
    "Z can be represented by a $N * K$ where $N=100$ and $K=36$"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 44,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each image in our simulated data set is the superposition of four base images#\n",
    "# Number of images/ data points\n",
    "num_objects=100\n",
    "\n",
    "#Dimension of image (6x6)\n",
    "object_dim  = 6*6\n",
    "\n",
    "#Covariance matrix for images/ white noise\n",
    "sigma_x_orig = 0.5\n",
    "I = sigma_x_orig * np.identity(object_dim)\n",
    "\n",
    "#z_i - binary feature matrix (1 x 4) - each entry set to 1 with probability 0.5 and 0 otherwise#\n",
    "#x is data variable - each row correspondes to a superimposed built from a random combination of latent features#\n",
    "#with white noise added - x is built with multivariate gaussian#\n",
    "x = np.zeros((100,36))\n",
    "z = np.zeros((100,4))\n",
    "\n",
    "for i in range(0,num_objects):\n",
    "    z[i,:] = np.array([bernoulli.rvs(p=0.5, size=4)])\n",
    "    x[i,:] = mvtnorm.rvs(np.dot(z[i,:],W), I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the two examples simulated images"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 42,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAC0CAYAAABIZe24AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADldJREFUeJzt3V1slnWax/HfhVIC1J0YMEhoZsaWjA3DOxEhbWOHyEuY\nZPZAD3adRDKSOXIzRDcTE05MT4j1hGA8MgMbZlZ2Vklc2IR1WyKdDcOLxEIVBLQys/hCKypZKJJl\ndrj2oE+rA1Oe+4H7fz9XH76fpOn94P/5X//ixa93794v5u4CAMQyodoLAADciHAGgIAIZwAIiHAG\ngIAIZwAIiHAGgIDuzmsiM+OcPCTl7lZ0TfoaqY3V17mFsyR98cUXmcd2dnbqueeeq2j+5ubmSpek\ny5cva+rUqRW9Z9euXRWN37p1q9avX1/Re65du1bR+G3btumpp56q6D2SdODAgYrGd3d3a+XKlRW9\nZ+LEiRWNf/PNN7VmzZqK3vPss89WND5Ply5dqmj8pk2btHHjxszjBwcHK12StmzZog0bNlT0ngce\neKDiOh0dHXr++eczj1+3bl3FNfr6+rRgwYKK3lNpzx09elSLFi2q6D29vb0VjZekgYEB3X///ZnH\n9/X1jfnfOKwBAAERzgAQUNXCuaWlpZA6lf74cysq/XEpag1JamxsTF5j9uzZyWtUU1tbW/IaDz/8\ncPIakvTII48krzFjxozkNSo51HA76uvrc5urauHc2tpaSJ26urrkNRYvXpy8RlHh3NTUlLwG4Xz7\nli1blryGJLW3tyevUURwzpw5M3kNqUbCGQAwNsIZAALKdCqdmf1R0v9IuibpT+6+NOWigKLQ24gq\n63nO1yS1u/uFlIsBqoDeRkhZD2tYBWOB8YTeRkhZm9IldZvZETP7ecoFAQWjtxFS1sMaLe5+zszu\n03Ajn3T3/dcP6uzs/OYNLS2FnS6H2tPf36/+/v4iSpXt7U2bNo1ut7W1FXKqHGrT0NCQhoaGMo3N\nFM7ufq70+byZvSFpqaQbwrnSe2UAY5k9e/ZfnA/d1dWVpE6W3q7kPhnAzdTX1//FudA3u69K2cMa\nZjbFzOpL21MlrZJ0/PaXCVQXvY3Isuw5z5D0RunWiXdLetXd0+zGAMWitxFW2XB29z9IWljAWoBC\n0duIjFOIACAgwhkAAiKcASAgwhkAAiKcASAgwhkAAiKcASAgwhkAAsp646NM+vr68pzuBjt27Eg6\n/4idO3cmrzEwMJC8hiQ9/vjjyWvs27cveY1qeuihh5LO/+qrryadf8T69euT13jmmWeS15CkEydO\nJK+xZ8+e5DVuhj1nAAiIcAaAgAhnAAiIcAaAgAhnAAiIcAaAgAhnAAgoczib2QQz6zWz3SkXBBSJ\nvkZUlew5b5D0fqqFAFVCXyOkTOFsZg2S1kr6VdrlAMWhrxFZ1j3nzZJ+KckTrgUoGn2NsMqGs5n9\nWNKgux+TZKUPYFyjrxFdlhsftUj6iZmtlTRZ0j1m9mt3f/L6gdu3bx/dXrBggRYu5MHGuDWffPKJ\nPv3005QlMvf1+fPnR7enTJmiqVOnplwXatjVq1d19erVTGPLhrO7b5S0UZLM7BFJ//jXGliS1q1b\nV8EygbE1NDSooaFh9PWRI0dynb+Svr7vvvtyrY07V11dnerq6kZfX758ecyxnOcMAAFVdD9nd/+d\npN8lWgtQFfQ1ImLPGQACIpwBICDCGQACIpwBICDCGQACIpwBICDCGQACIpwBICBzz+eGXGbmTz/9\ndC5zjeWzzz5LOv+I1atXJ69x8uTJ5DUk6cqVK8lrFPH39dhjj8ndC785kZl5Z2dn0hovvPBC0vlH\nPPnkX706PVfTp09PXkOSWltbk9eYPHly8hrLli0bs6/ZcwaAgAhnAAiIcAaAgAhnAAiIcAaAgAhn\nAAiIcAaAgAhnAAio7JNQzGySpP+SVFcav9PdO1IvDEiN3kZkWR7w+r9m9iN3/9rM7pL0ezP7D3d/\nu4D1AcnQ24gs02ENd/+6tDlJw4GezzXfQJXR24gqUzib2QQzOyppQFK3u+f7nHqgSuhtRJXp6dvu\nfk3SIjP7G0n/ZmZz3P3968e9/fY3Pw3OmjVLs2bNym2huLMcP35cJ06cSF4nS293d3ePbjc2Nqqp\nqSn5ulCb3nnnHfX29mYamymcR7j7RTPbJ2mNpBvCeenSpZVMB4xp7ty5mjt37ujr1157LWm9m/X2\nypUrk9bGnWPJkiVasmTJ6OutW7eOObbsYQ0zm25m3yltT5a0UtKp218mUF30NiLLsuc8U9J2M5ug\n4TD/V3ffk3ZZQCHobYSV5VS69yQtLmAtQKHobUTGFYIAEBDhDAABEc4AEBDhDAABEc4AEBDhDAAB\nEc4AEBDhDAABVXRvjXJS3+ho/vz5Secf0dPTk7zGggULkteQpAkT0n//rfV7qsyZMyfp/CtWrEg6\n/4i+vr7kNbZv3568hiS9+OKLyWu8/PLLyWvcDHvOABAQ4QwAARHOABAQ4QwAARHOABAQ4QwAARHO\nABBQlsdUNZjZW2Z2wszeM7NfFLEwIDV6G5FluQjl/yQ96+7HzKxe0jtm1uXuPGsN4x29jbDK7jm7\n+4C7HyttD0k6KSntpYBAAehtRFbRMWcz+76khZIOp1gMUC30NqLJfG+N0o99OyVtKO1l3GDv3r2j\n242NjWpsbLztBeLOdPDgQR08eLCQWuV6e8eOHaPb8+bN07x58wpZF2pPT09P5nv3ZApnM7tbw837\nG3ffNda4Rx99NFNRoJzly5dr+fLlo683b96cpE6W3n7iiSeS1Madp729Xe3t7aOvOzo6xhyb9bDG\nNknvu/uW21oZEA+9jZCynErXIumnklaY2VEz6zWzNemXBqRFbyOysoc13P33ku4qYC1AoehtRMYV\nggAQEOEMAAERzgAQEOEMAAERzgAQEOEMAAERzgAQEOEMAAFlvvFRFhMnTsxzuhtcuXIl6fwjmpqa\nkteYNauYO1Pu2bMneQ13T16jml555ZWk81+4cCHp/CP279+fvMbrr7+evIYk3XvvvclrrF27NnmN\nm2HPGQACIpwBICDCGQACIpwBICDCGQACIpwBICDCGQACyvIklK1mNmhm7xaxIKAo9DYiy7Ln/E+S\nVqdeCFAF9DbCKhvO7r5fUjGXMAEForcRGcecASAgwhkAAsr1xkddXV2j201NTYXcQAi16aOPPtKZ\nM2eqvQxJ0unTp0e3p02bpunTp1dxNRjPvvzyS3311VeZxmYNZyt93NSqVasyTgfc3PXf3Pfu3Zuq\nVNnefvDBB1PVxh1m2rRpmjZt2ujr/v7+McdmOZVuh6QDkn5gZmfN7Gd5LBKoNnobkZXdc3b3J4pY\nCFA0ehuR8QtBAAiIcAaAgAhnAAiIcAaAgAhnAAiIcAaAgAhnAAiIcAaAgAhnAAjI3D2ficzymegm\nXnrppdQlJEkHDx5MXqO1tTV5DUlqa2tLXmPevHnJa5iZ3L3s/V0S1PWFCxcmrTFp0qSk848oohda\nWlqS15Ck+fPnJ6/R09OTvMb69evH7Gv2nAEgIMIZAAIinAEgIMIZAAIinAEgIMIZAAIinAEgoEzh\nbGZrzOyUmX1gZs+lXhRQBPoakWV5huAESS9LWi3ph5L+3syaUy8MSIm+RnRZ9pyXSvrQ3f/b3f8k\n6beS/jbtsoDk6GuEliWcZ0n6+FuvPyn9GTCe0dcIrezTt4Fq6OnpKeTeBlmcO3dudLu+vl733HNP\nFVeD8ezUqVM6ffp0prFZwvlTSd/91uuG0p8BybS3t6u9vX30dUdHR94lMvf1zJkz866NO1Rzc7Oa\nm7/51cbu3bvHHJvlsMYRSbPN7HtmVifp7ySNPSMwPtDXCK3snrO7/9nM/kFSl4bDfKu7n0y+MiAh\n+hrRZTrm7O5vSnow8VqAQtHXiIwrBAEgIMIZAAIinAEgIMIZAAKq+XD+8MMPk9cYHBxMXuODDz5I\nXkOSjhw5krxGlItLUrl06VLyGhcvXkxeQ5LOnj2bvMbx48eT1zh06FDyGtLwRSZ5IZxz8Pnnnyev\nUcTXIRHOeRgaGkpeo6hw/vjjj8sPuk1FhPPhw4eT15CU+eq/LGo+nAFgPCKcASAgc/d8JjLLZyJg\nDO5uRdekr5HaWH2dWzgDAPLDYQ0ACIhwBoCAqhLORTxY08y2mtmgmb2bYv5SjQYze8vMTpjZe2b2\niwQ1JpnZYTM7WqrxfN41vlVrgpn1mlmyW2ea2R/NrK/09bydqk410NcV16mZ3k7S1+5e6IeGvyH0\nS/qepImSjklqTlCnVdJCSe8m/Frul7SwtF0v6XSir2VK6fNdkg5JWpro63lG0j9L2p3w7+yMpHtT\nzV+tD/r6lmvVRG+n6Otq7DkX8mBNd98v6ULe815XY8Ddj5W2hySdVILn0Ln716XNSRq+zWvuv8U1\nswZJayX9Ku+5ry+l2jycRl/fWq1a6e3c+7oa/0hq8sGaZvZ9De/R5H4pUulHsqOSBiR1u3uKy/g2\nS/qlEvzjuI5L6jazI2b288S1ikRf39r8tdLbufd1Le7BFM7M6iXtlLShtKeRK3e/5u6LNPycu4fN\nbE6e85vZjyUNlvaWrPSRSou7L9bwnszTZtaasBZuQ+q+lmqqt3Pv62qEc009MNbM7tZwA//G3Xel\nrOXuFyXtk7Qm56lbJP3EzM5I+hdJPzKzX+dcQ5Lk7udKn89LekPDhwNqAX19G8Z7b6fo62qEc5EP\n1ky9FyhJ2yS97+5bUkxuZtPN7Dul7cmSVkrK79ZXktx9o7t/190bNfz/4y13fzLPGpJkZlNKe2My\ns6mSVklKf9ebYtDXFaqV3k7V14WHs7v/WdLIgzVPSPqtJ3iwppntkHRA0g/M7KyZ/SxBjRZJP5W0\nonQKTa+Z5f2df6akfWZ2TMPH/f7T3ffkXKMoMyTtLx1jPCTp3929q8prygV9fUtqpbeT9DWXbwNA\nQPxCEAACIpwBICDCGQACIpwBICDCGQACIpwBICDCGQACIpwBIKD/B58VU6oujPcdAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cd746a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "a=fig.add_subplot(1,2,1)\n",
    "plt.imshow(np.matrix(x[0,:]).reshape(6,6),cmap=plt.get_cmap('gray'),  interpolation='nearest',origin='lower')\n",
    "a=fig.add_subplot(1,2,2)\n",
    "plt.imshow(np.matrix(x[1,:]).reshape(6,6),cmap=plt.get_cmap('gray'),  interpolation='nearest',origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian Buffet Process Prior\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indian Buffet Process Function\n",
    "\n",
    "def sampleIBP(alpha, num_objects):\n",
    "    \n",
    "    # Initializing storage for results\n",
    "    result = np.zeros([num_objects, 1000])\n",
    "    # Draw from the prior for alpha\n",
    "    t = np.random.poisson(alpha)\n",
    "    # Filling in first row of result matrix\n",
    "    result[0, 0:t] = np.ones([1, t])\n",
    "    # Initializing K+\n",
    "    K_plus = t\n",
    "    \n",
    "\n",
    "    for i in range(1, num_objects):\n",
    "        for j in range(0, K_plus):\n",
    "            p = np.array([np.log(np.sum(result[0:i,j])) - np.log(i+1), \n",
    "                          np.log(i+1 - np.sum(result[0:i, j])) - np.log(i+1)])\n",
    "            p = np.exp(p - max(p))\n",
    "\n",
    "            if(np.random.uniform() < p[0]/np.sum(p)):\n",
    "                result[i, j] = 1\n",
    "            else:\n",
    "                result[i, j] = 0\n",
    "        t = np.random.poisson(alpha/(i+1))\n",
    "        x = K_plus + 1\n",
    "        y = K_plus + t\n",
    "        result[i, (x-1):y] = np.ones([1, t]) # NEED TO CHECK DIM\n",
    "        K_plus = K_plus+t\n",
    "    result = result[:, 0:K_plus]\n",
    "    return list([result, K_plus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 76,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A recursive function that computes matrix M\n",
    "def Mcalc(Z, K_plus, new_dishes, sigma_X, sigma_A):\n",
    "    part1 = np.dot(np.transpose(Z[:,0:(K_plus+new_dishes)]), Z[:,0:(K_plus+new_dishes)])\n",
    "    part2 = (sigma_X/sigma_A)**2 * np.identity(K_plus+new_dishes)\n",
    "    result = np.linalg.inv(part1+part2)\n",
    "    return(result)\n",
    "\n",
    "\n",
    "# Function for efficiently computing the inverse of M\n",
    "def calcInverse(Z, M, i, k, val):\n",
    "    M_i = M - (np.dot(np.dot(np.dot(M, Z[i,:].T), Z[i,:]), M)) / (np.dot(np.dot(Z[i,:], M), Z[i,:].T) - 1)\n",
    "    Z[i, k] = val\n",
    "    M = M_i - (np.dot(np.dot(np.dot(M_i, Z[i,:].T), Z[i,:]), M_i)) / (np.dot(np.dot(Z[i,:], M_i), Z[i,:].T) + 1)\n",
    "    Inv = M\n",
    "    return(Inv)\n",
    "\n",
    "# The function returns the log likelihood\n",
    "def likelihood(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    part1 = - (num_objects*(object_dim/2)*np.log(2*np.pi))\n",
    "    part2 = - (num_objects-K_plus)* object_dim *np.log(sigma_X) \n",
    "    part3 = - (object_dim*K_plus)*np.log(sigma_A) \n",
    "    part4 = - (object_dim/2)* np.log(np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))) \n",
    "    part5 = (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(np.transpose(X),(np.identity(num_objects) - np.dot(np.dot(Z,M),np.transpose(Z)))),X))\n",
    "    total = part1+part2+part3+part4+part5\n",
    "    return(total)\n",
    "\n",
    "# The function samples a new value of sigma_A using metropolis algorithim\n",
    "def met_sigma_A(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, X):\n",
    "    \n",
    "    #Determine M based on sigma_A\n",
    "    #Determine current likelihood based on M and sigma_A\n",
    "    M = Mcalc(Z, K_plus, new_dishes, sigma_X, sigma_A)\n",
    "    l_curr = likelihood1(X, Z[:,0:(K_plus+new_dishes)], M, sigma_A, sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    #sample new value from symmetric distribution close to current value\n",
    "    if unif.rvs(0,1)<0.5:\n",
    "        new_sigma_A = sigma_A - unif.rvs(0,1)/20\n",
    "    else:\n",
    "        new_sigma_A = sigma_A + unif.rvs(0,1)/20\n",
    "    \n",
    "    #Determine M based on new_sigma_A\n",
    "    #Determine current likelihood based on M and new_sigma_A\n",
    "    M = Mcalc(Z, K_plus, new_dishes, sigma_X, new_sigma_A)\n",
    "    l_new = likelihood1(x, Z[:,0:(K_plus+new_dishes)], M, new_sigma_A, sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    acceptance_ratio = np.exp(min(0,l_new - l_curr))\n",
    "    \n",
    "    if unif.rvs(0,1)<acceptance_ratio:\n",
    "        return(new_sigma_A)\n",
    "    else:\n",
    "        return(sigma_A)\n",
    "\n",
    "# The function samples a new value of sigma_X using metropolis algorithim\n",
    "def met_sigma_X(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, X):\n",
    "    \n",
    "    #Determine M based on sigma_X\n",
    "    #Determine current likelihood based on M and sigma_X\n",
    "    M = Mcalc(Z, K_plus, new_dishes, sigma_X, sigma_A)\n",
    "    l_curr = likelihood1(X, Z[:,0:(K_plus+new_dishes)], M, sigma_A, sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    #sample new value from symmetric distribution close to current value\n",
    "    if unif.rvs(0,1)<0.5:\n",
    "        new_sigma_X = sigma_X - unif.rvs(0,1)/20\n",
    "    else:\n",
    "        new_sigma_X = sigma_X + unif.rvs(0,1)/20\n",
    "    \n",
    "    #Determine M based on new_sigma_A\n",
    "    #Determine current likelihood based on M and new_sigma_A\n",
    "    M = Mcalc(Z, K_plus, new_dishes, new_sigma_X, sigma_A)\n",
    "    l_new = likelihood1(X, Z[:,0:(K_plus+new_dishes)], M, sigma_A, new_sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    acceptance_ratio = np.exp(min(0,l_new - l_curr))\n",
    "    \n",
    "    if unif.rvs(0,1)<acceptance_ratio:\n",
    "        return(new_sigma_X)\n",
    "    else:\n",
    "        return(sigma_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Mcalc Function\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Mcalc(Z, K_plus, new_dishes, sigma_X, sigma_A):\n",
    "    part1 = np.dot(np.transpose(Z[:,0:(K_plus+new_dishes)]), Z[:,0:(K_plus+new_dishes)])\n",
    "    part2 = (sigma_X/sigma_A)**2 * np.identity(K_plus+new_dishes)\n",
    "    result = np.linalg.inv(part1+part2)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Generation\n",
=======
    "Likelihood Function \n",
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
    "===="
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 81,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define the likelihood function ##\n",
    "# The function returns the log likelihood\n",
    "def likelihood(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    part1 = - (num_objects*(object_dim/2)*np.log(2*np.pi))\n",
    "    part2 = - (num_objects-K_plus)* object_dim *np.log(sigma_X) \n",
    "    part3 = - (object_dim*K_plus)*np.log(sigma_A) \n",
    "    part4 = - (object_dim/2)* np.log(np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))) \n",
    "    part5 = (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(np.transpose(X),(np.identity(num_objects) - np.dot(np.dot(Z,M),np.transpose(Z)))),X))\n",
    "    total = part1+part2+part3+part4+part5\n",
    "    return(total)\n",
    "\n",
    "def likelihood1(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    log_ll = -1 * num_objects * object_dim * .5 * np.log(2*np.pi) - 1 * (num_objects - K_plus) * object_dim * np.log(sigma_X) - K_plus * object_dim * np.log(sigma_A) - object_dim * .5 * np.log(np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))) + (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(X.T, np.eye(num_objects) - np.dot(Z, np.dot(M, Z.T))), X))\n",
    "    return(log_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sampler\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 76,
=======
   "execution_count": 83,
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "At iteration 0 : K_plus is 7 , alpha is 1 , new_dishes is 0\n",
      "At iteration 1 : K_plus is 7 , alpha is 1.5543860487706072 , new_dishes is 0\n",
      "At iteration 2 : K_plus is 7 , alpha is 1.5202703099972645 , new_dishes is 0\n",
      "At iteration 3 : K_plus is 6 , alpha is 1.2095827573650075 , new_dishes is 0\n",
      "At iteration 4 : K_plus is 6 , alpha is 1.1381027045659449 , new_dishes is 0\n",
      "At iteration 5 : K_plus is 6 , alpha is 1.8567765056223773 , new_dishes is 0\n",
      "At iteration 6 : K_plus is 6 , alpha is 1.1561434148824912 , new_dishes is 0\n",
      "At iteration 7 : K_plus is 6 , alpha is 0.4328848711319328 , new_dishes is 0\n",
      "At iteration 8 : K_plus is 6 , alpha is 0.5410290431832446 , new_dishes is 0\n",
      "At iteration 9 : K_plus is 6 , alpha is 0.6498235276016231 , new_dishes is 0\n",
      "At iteration 10 : K_plus is 6 , alpha is 1.3984398523229251 , new_dishes is 0\n",
      "At iteration 11 : K_plus is 6 , alpha is 1.5937895147850267 , new_dishes is 0\n",
      "At iteration 12 : K_plus is 6 , alpha is 0.9882342272727583 , new_dishes is 0\n",
      "At iteration 13 : K_plus is 7 , alpha is 0.7691979289352908 , new_dishes is 0\n",
      "At iteration 14 : K_plus is 7 , alpha is 0.6515735836301174 , new_dishes is 0\n",
      "At iteration 15 : K_plus is 8 , alpha is 1.6560027781627238 , new_dishes is 0\n",
      "At iteration 16 : K_plus is 8 , alpha is 2.1347513685216257 , new_dishes is 0\n",
      "At iteration 17 : K_plus is 8 , alpha is 1.726027153676019 , new_dishes is 0\n",
      "At iteration 18 : K_plus is 8 , alpha is 1.3604707356771795 , new_dishes is 0\n",
      "At iteration 19 : K_plus is 8 , alpha is 2.070139589885156 , new_dishes is 0\n",
      "At iteration 20 : K_plus is 10 , alpha is 1.6428243468078776 , new_dishes is 0\n",
      "At iteration 21 : K_plus is 12 , alpha is 1.1287151959607922 , new_dishes is 0\n",
      "At iteration 22 : K_plus is 14 , alpha is 1.6670767593470515 , new_dishes is 0\n",
      "At iteration 23 : K_plus is 14 , alpha is 1.960909681246131 , new_dishes is 0\n",
      "At iteration 24 : K_plus is 19 , alpha is 3.311594861073722 , new_dishes is 0\n",
      "At iteration 25 : K_plus is 20 , alpha is 3.428026715951379 , new_dishes is 0\n"
=======
      "At iteration 0 : K_plus is 6 , alpha is 1\n",
      "At iteration 1 : K_plus is 4 , alpha is 0.6732612303922842\n",
      "At iteration 2 : K_plus is 1 , alpha is 0.15729049167535386\n",
      "At iteration 3 : K_plus is 1 , alpha is 0.5036480714872699\n",
      "At iteration 4 : K_plus is 1 , alpha is 0.09825030371013466\n",
      "At iteration 5 : K_plus is 1 , alpha is 0.1477739137441493\n",
      "At iteration 6 : K_plus is 1 , alpha is 0.16633553029254156\n",
      "At iteration 7 : K_plus is 1 , alpha is 0.31199371528163056\n",
      "At iteration 8 : K_plus is 1 , alpha is 0.38577823739546163\n",
      "At iteration 9 : K_plus is 1 , alpha is 0.34984253884049055\n",
      "At iteration 10 : K_plus is 1 , alpha is 0.45811057185330595\n",
      "At iteration 11 : K_plus is 1 , alpha is 0.09977256434306284\n",
      "At iteration 12 : K_plus is 1 , alpha is 0.13495512657459652\n",
      "At iteration 13 : K_plus is 1 , alpha is 0.2975420204833413\n",
      "At iteration 14 : K_plus is 1 , alpha is 0.24213088041099243\n",
      "At iteration 15 : K_plus is 1 , alpha is 0.531721759600442\n",
      "At iteration 16 : K_plus is 1 , alpha is 0.3086177651203455\n",
      "At iteration 17 : K_plus is 1 , alpha is 0.24473866258194654\n",
      "At iteration 18 : K_plus is 1 , alpha is 0.3714366015601762\n",
      "At iteration 19 : K_plus is 1 , alpha is 0.31990507758694375\n",
      "At iteration 20 : K_plus is 1 , alpha is 0.13697223144092527\n",
      "At iteration 21 : K_plus is 1 , alpha is 0.20707463439524235\n",
      "At iteration 22 : K_plus is 1 , alpha is 0.37329793978882136\n",
      "At iteration 23 : K_plus is 1 , alpha is 0.3934904068660525\n",
      "At iteration 24 : K_plus is 1 , alpha is 0.16427383200955187\n",
      "At iteration 25 : K_plus is 1 , alpha is 0.3263769203204054\n",
      "At iteration 26 : K_plus is 1 , alpha is 0.41194609832234813\n",
      "At iteration 27 : K_plus is 1 , alpha is 0.1902452006498307\n",
      "At iteration 28 : K_plus is 1 , alpha is 0.5076247479299619\n",
      "At iteration 29 : K_plus is 1 , alpha is 0.33339904964708955\n",
      "At iteration 30 : K_plus is 1 , alpha is 0.5850774783765817\n",
      "At iteration 31 : K_plus is 1 , alpha is 0.1835482195455372\n",
      "At iteration 32 : K_plus is 1 , alpha is 0.3055520265912563\n"
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (100,23) into shape (100,20)",
     "output_type": "error",
     "traceback": [
<<<<<<< HEAD
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-3d9357c01f20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mBURN_IN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0ms_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms_counter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mchain_Z\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_counter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mchain_K\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_counter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK_plus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mchain_sigma_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_counter\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigma_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (100,23) into shape (100,20)"
=======
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-c265f4c62a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk_i\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_plus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sunith/anaconda/lib/python3.5/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
     ]
    }
   ],
   "source": [
    "# GENERAL FUNCTION SAMPLER\n",
    "\n",
    "# Harmonic number or N\n",
    "HN = 0\n",
    "for i in range(0, num_objects):\n",
    "    HN = HN + 1/(i+1)\n",
    "\n",
    "E = 1000\n",
    "BURN_IN = 0\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "# Initializing values for use in our chain\n",
    "sigma_A = 1\n",
    "sigma_X = 1\n",
    "# Poisson rate\n",
    "alpha = 1\n",
    "# Prespecified maximum number of latent features\n",
    "K_inf = 20\n",
    "# Indian Buffet Process Prior\n",
    "Z, K_plus = sampleIBP(alpha, num_objects)\n",
    "# Initialization of our chain for Z\n",
    "chain_Z = np.zeros([SAMPLE_SIZE, num_objects, K_inf])\n",
    "# Initialization of our chain for K\n",
    "chain_K = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for sigma_X\n",
    "chain_sigma_X = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for sigma_A\n",
    "chain_sigma_A = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for alpha\n",
    "chain_alpha = np.zeros([SAMPLE_SIZE, 1])\n",
    "\n",
    "# Initializing storage for post burn-in samples\n",
    "s_counter = 0\n",
    "for e in range(0, E):\n",
    "    if(e > BURN_IN):\n",
    "        s_counter = s_counter + 1\n",
    "        chain_Z[s_counter, :, 0:K_plus] = Z[:, 0:K_plus]\n",
    "        chain_K[s_counter] = K_plus\n",
    "        chain_sigma_X[s_counter] = sigma_X\n",
    "        chain_sigma_A[s_counter] = sigma_A\n",
    "        chain_alpha[s_counter] = alpha\n",
    "    print(\"At iteration\", e, \": K_plus is\", K_plus, \", alpha is\", alpha, \", new_dishes is\", new_dishes) \n",
    "\n",
    "    for i in range(0, num_objects):\n",
    "        # M matrix will be handy for future computations\n",
    "        M = Mcalc(Z, K_plus, 0, sigma_X, sigma_A)\n",
    "        #M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "        for k in range(0, K_plus):\n",
    "            # Checking to make sure that k < K_plus\n",
    "            if k >= K_plus:\n",
    "                break\n",
    "            if Z[i, k] > 0:\n",
    "                # Take care of singularities\n",
    "                if (np.sum(Z[:, k]) - Z[i, k]) <= 0: \n",
    "                    Z[i, k] = 0\n",
    "                    Z[:, k:(K_plus - 1)] = Z[:, (k+1):K_plus]\n",
    "                    K_plus = K_plus - 1\n",
<<<<<<< HEAD
    "                    Z = Z[:, 0:K_plus]\n",
    "                    M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
=======
    "                    M = Mcalc(Z, K_plus, 0, sigma_X, sigma_A)\n",
    "                    #M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
    "                    continue\n",
    "             \n",
    "            # This is where he has his calcInverse functions to \n",
    "            # speed up inverse calculations. I just use inverse\n",
    "            # of Z matrix below\n",
    "            M1 = calcInverse(Z[:, 0:K_plus], M, i, k, 1)\n",
    "            M2 = calcInverse(Z[:, 0:K_plus], M, i, k, 0)\n",
    "\n",
    "            # Compute conditional distributions for the current cell in Z\n",
    "            P = np.zeros(2)\n",
    "            Z[i, k] = 1\n",
<<<<<<< HEAD
    "            P[0] = likelihood1(x, Z[:, 0:K_plus], M1, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(np.sum(Z[:, k]) - 1) - np.log(num_objects)\n",
    "\n",
    "            Z[i, k] = 0\n",
    "            P[1] = likelihood1(x, Z[:, 0:K_plus], M2, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(num_objects - np.sum(Z[:,k])) - np.log(num_objects)\n",
=======
    "            P.append(likelihood(x, Z[:, 0:K_plus], M1, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(sum(Z[:, k]) - Z[i, k]) - np.log(num_objects))\n",
    "            #P.append(likelihood1(x, Z[:, 0:K_plus], M1, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(sum(Z[:, k]) - Z[i, k]) - np.log(num_objects))\n",
    "\n",
    "            Z[i, k] = 0\n",
    "            P.append(likelihood(x, Z[:, 0:K_plus], M2, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(num_objects - sum(Z[:,k])) - np.log(num_objects))\n",
    "            #P.append(likelihood1(x, Z[:, 0:K_plus], M2, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(num_objects - sum(Z[:,k])) - np.log(num_objects))\n",
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
    "            \n",
    "            P = np.exp(P - np.max(P))\n",
    "\n",
    "            # Sample from the conditional\n",
    "            if np.random.uniform() < (P[0] / (np.sum(P))):\n",
    "                Z[i, k] = 1\n",
    "                M = M1\n",
    "            else:\n",
    "                Z[i, k] = 0\n",
    "                M = M2\n",
    "        \n",
    "        # Sample the number of new dishes for the current object\n",
    "        trun = np.zeros([1, 5])\n",
    "        alpha_N = alpha / num_objects\n",
<<<<<<< HEAD
    "\n",
    "\n",
    "################### ERROR IN DIMENSIONALITY RIGHT HERE ###########################        \n",
    "        for k_i in range(5):\n",
    "            Z_temp = Z        \n",
    "            if k_i > 0:\n",
    "                z = np.zeros((num_objects, k_i))\n",
    "                Z_temp = np.column_stack((Z_temp, z))\n",
    "                Z_temp[i, K_plus:(K_plus+k_i)] = 1\n",
    "            M = np.linalg.inv(np.dot(Z_temp[:, 0:(K_plus + k_i)].T, Z_temp[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i)) # MINUS ONE TO FIX DIMENSIONALITY MAY BE INCORRECT\n",
    "            trun[0, k_i] = k_i * np.log(alpha_N) - alpha_N - np.log(np.math.factorial(k_i)) + likelihood1(x, Z_temp[:, 0:(K_plus + k_i)], M, sigma_A, sigma_X, K_plus + k_i, num_objects, object_dim)\n",
    "        #Z[i, K_plus:(K_plus+4)] = 0\n",
=======
    " \n",
    "        for k_i in range(0, 5):\n",
    "            if k_i > 0:\n",
    "                z = np.repeat(0, np.shape(Z)[0])\n",
    "                Z = np.column_stack((Z, z))\n",
    "                Z[i, K_plus:(K_plus+k_i)] = 1\n",
    "            M = Mcalc(Z, K_plus, k_i, sigma_X, sigma_A) \n",
    "            #M = np.linalg.inv(np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i)) # MINUS ONE TO FIX DIMENSIONALITY MAY BE INCORRECT\n",
    "            trun[0, k_i] = k_i * np.log(alpha_N) - alpha_N - np.log(np.math.factorial(k_i)) + likelihood(x, Z[:, 0:(K_plus + k_i)], M, sigma_A, sigma_X, K_plus + k_i, num_objects, object_dim)\n",
    "            #trun[0, k_i] = k_i * np.log(alpha_N) - alpha_N - np.log(np.math.factorial(k_i)) + likelihood1(x, Z[:, 0:(K_plus + k_i)], M, sigma_A, sigma_X, K_plus + k_i, num_objects, object_dim)\n",
    "        Z[i, K_plus:(K_plus+4)] = 0\n",
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
    "        trun = np.exp(trun - np.max(trun))\n",
    "        trun = trun/np.sum(trun)\n",
    "        p = np.random.uniform()\n",
    "        t = 0\n",
    "        new_dishes = 0\n",
    "        for k_i in range(0,5):\n",
    "            t = t + trun[0, k_i]\n",
    "            if p < t:\n",
    "                new_dishes = k_i\n",
    "                break\n",
    "        if(new_dishes > 0):\n",
    "            z = np.zeros((num_objects, new_dishes))\n",
    "            Z = np.column_stack([Z, z])\n",
    "            Z[i, K_plus:(K_plus + new_dishes)] = 1\n",
    "        K_plus = K_plus + new_dishes\n",
    "    \n",
    "    # Metropolis steps for sampling sigma_X and sigma_A\n",
    "    N_sigma_X = met_sigma_X(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, x)\n",
    "\n",
    "    sigma_A = met_sigma_A(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, x)\n",
    "    \n",
    "    sigma_X = N_sigma_X\n",
    "\n",
    "    # Sample alpha from its conditional posterior\n",
    "    alpha = np.random.gamma(1 + K_plus, 1/(1+HN))\n"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_plus\n",
    "#np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]).shape\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=float64), 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for k in range(10):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def profiler(n):\n",
    "    # GENERAL FUNCTION SAMPLER\n",
    "\n",
    "    # Harmonic number or N\n",
    "    HN = 0\n",
    "    for i in range(0, num_objects):\n",
    "        HN = HN + 1/(i+1)\n",
    "\n",
    "    E = n\n",
    "    BURN_IN = 0\n",
    "    SAMPLE_SIZE = n\n",
    "\n",
    "    # Initializing values for use in our chain\n",
    "    sigma_A = 1\n",
    "    sigma_X = 1\n",
    "    # Poisson rate\n",
    "    alpha = 1\n",
    "    # Prespecified maximum number of latent features\n",
    "    K_inf = 10\n",
    "    # Indian Buffet Process Prior\n",
    "    Z, K_plus = sampleIBP(alpha, num_objects)\n",
    "    # Initialization of our chain for Z\n",
    "    chain_Z = np.zeros([SAMPLE_SIZE, num_objects, K_inf])\n",
    "    # Initialization of our chain for K\n",
    "    chain_K = np.zeros([SAMPLE_SIZE, 1])\n",
    "    # Initialization of our chain for sigma_X\n",
    "    chain_sigma_X = np.zeros([SAMPLE_SIZE, 1])\n",
    "    # Initialization of our chain for sigma_A\n",
    "    chain_sigma_A = np.zeros([SAMPLE_SIZE, 1])\n",
    "    # Initialization of our chain for alpha\n",
    "    chain_alpha = np.zeros([SAMPLE_SIZE, 1])\n",
    "\n",
    "    # Initializing storage for post burn-in samples\n",
    "    s_counter = 0\n",
    "    for e in range(0, E):\n",
    "        if(e > BURN_IN):\n",
    "            s_counter = s_counter + 1\n",
    "            chain_Z[s_counter, :, 0:K_plus] = Z[:, 0:K_plus]\n",
    "            chain_K[s_counter] = K_plus\n",
    "            chain_sigma_X[s_counter] = sigma_X\n",
    "            chain_sigma_A[s_counter] = sigma_A\n",
    "            chain_alpha[s_counter] = alpha\n",
    "        print(\"At iteration\", e, \": K_plus is\", K_plus, \", alpha is\", alpha) \n",
    "\n",
    "        for i in range(0, num_objects):\n",
    "            # M matrix will be handy for future computations\n",
    "            # SOMETIMES SINGULAR, NEED TO FIX\n",
    "            M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "            for k in range(0, K_plus):\n",
    "                # Checking to make sure that k < K_plus\n",
    "                if k+1 > K_plus:\n",
    "                    break\n",
    "                if Z[i, k] > 0:\n",
    "                    # Take care of singularities\n",
    "                    if np.sum(Z[:, k]) - Z[i, k] <= 0:\n",
    "                        Z[i, k] = 0\n",
    "                        Z[:, k:(K_plus - 1)] = Z[:, (k+1):K_plus]\n",
    "                        K_plus = K_plus - 1\n",
    "                        M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "                        continue\n",
    "             \n",
    "                # This is where he has his calcInverse functions to \n",
    "                # speed up inverse calculations. I just use inverse\n",
    "                # of Z matrix below\n",
    "                M1 = calcInverse(Z[:, 0:K_plus], M, i, k, 1)\n",
    "                M2 = calcInverse(Z[:, 0:K_plus], M, i, k, 0)\n",
    "\n",
    "                # Compute conditional distributions for the current cell in Z\n",
    "                P = []\n",
    "                Z[i, k] = 1\n",
    "                P.append(likelihood1(x, Z[:, 0:K_plus], M1, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(sum(Z[:, k]) - Z[i, k]) - np.log(num_objects))\n",
    "\n",
    "                Z[i, k] = 0\n",
    "                P.append(likelihood1(x, Z[:, 0:K_plus], M2, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(num_objects - np.sum(Z[:,k])) - np.log(num_objects))\n",
    "            \n",
    "                P = np.exp(P - np.max(P))\n",
    "\n",
    "                # Sample from the conditional\n",
    "                if np.random.uniform() < P[0] / (P[0] + P[1]):\n",
    "                    Z[i, k] = 1\n",
    "                    M = M1\n",
    "                else:\n",
    "                    Z[i, k] = 0\n",
    "                    M = M2\n",
    "        \n",
    "            # Sample the number of new dishes for the current object\n",
    "            trun = np.zeros([1, 5])\n",
    "            alpha_N = alpha / num_objects\n",
    "\n",
    "\n",
    "################### ERROR IN DIMENSIONALITY RIGHT HERE ###########################        \n",
    "            for k_i in range(0, 5):\n",
    "                if k_i > 0:\n",
    "                    z = np.repeat(0, np.shape(Z)[0])\n",
    "                    Z = np.column_stack((Z, z))\n",
    "                    Z[i, K_plus:(K_plus+k_i)] = 1\n",
    "                M = np.linalg.inv(np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i)) # MINUS ONE TO FIX DIMENSIONALITY MAY BE INCORRECT\n",
    "                trun[0, k_i] = k_i * np.log(alpha_N) - alpha_N - np.log(np.math.factorial(k_i)) + likelihood1(x, Z[:, 0:(K_plus + k_i)], M, sigma_A, sigma_X, K_plus + k_i, num_objects, object_dim)\n",
    "            Z[i, K_plus:(K_plus+4)] = 0\n",
    "            trun = np.exp(trun - np.max(trun))\n",
    "            trun = trun/np.sum(trun)\n",
    "            p = np.random.uniform()\n",
    "            t = 0\n",
    "            for k_i in range(0,5):\n",
    "                t = trun[0, k_i]\n",
    "                if p < t:\n",
    "                    new_dishes = k_i\n",
    "                    break\n",
    "            Z[i, K_plus:(K_plus + new_dishes)] = 1\n",
    "            K_plus = K_plus + new_dishes\n",
    "    \n",
    "        # Metropolis steps for sampling sigma_X and sigma_A\n",
    "        sigma_X = met_sigma_X(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, x)\n",
    "\n",
    "        sigma_A = met_sigma_A(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, x)\n",
    "\n",
    "        # Sample alpha from its conditional posterior\n",
    "        alpha = gamma.rvs(a = 1 + K_plus, scale = 1/(1+HN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun -q -D profiler.prof profiler(int(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('profiler.prof')\n",
    "p.print_stats()\n",
    "pass"
   ]
=======
>>>>>>> b08ae5798e0d19683b9421a6345cb3572f6fbbef
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
