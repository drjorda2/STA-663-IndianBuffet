{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indian Buffet Process Prior\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indian Buffet Process Function\n",
    "\n",
    "def sampleIBP(alpha, num_objects):\n",
    "    \n",
    "    # Initializing storage for results\n",
    "    result = np.zeros([num_objects, 1000])\n",
    "    # Draw from the prior for alpha\n",
    "    t = np.random.poisson(alpha)\n",
    "    # Filling in first row of result matrix\n",
    "    result[0, 0:t] = np.ones([1, t])\n",
    "    # Initializing K+\n",
    "    K_plus = t\n",
    "    \n",
    "\n",
    "    for i in range(1, num_objects):\n",
    "        for j in range(0, K_plus):\n",
    "            p = np.array([np.log(np.sum(result[0:i,j])) - np.log(i+1), \n",
    "                          np.log(i+1 - np.sum(result[0:i, j])) - np.log(i+1)])\n",
    "            p = np.exp(p - max(p))\n",
    "\n",
    "            if(np.random.uniform() < p[0]/np.sum(p)):\n",
    "                result[i, j] = 1\n",
    "            else:\n",
    "                result[i, j] = 0\n",
    "        t = np.random.poisson(alpha/(i+1))\n",
    "        x = K_plus + 1\n",
    "        y = K_plus + t\n",
    "        result[i, (x-1):y] = np.ones([1, t]) # NEED TO CHECK DIM\n",
    "        K_plus = K_plus+t\n",
    "    result = result[:, 0:K_plus]\n",
    "    return list([result, K_plus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  1.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.]]), 5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleIBP(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Simplification\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for enhancing inverse process\n",
    "\n",
    "def calcInverse(Z, M, i, k, val):\n",
    "    M_i = M - (np.dot(np.dot(np.dot(M, Z[i,:].T), Z[i,:]), M)) / (np.dot(np.dot(Z[i,:], M), Z[i,:].T) - 1)\n",
    "    Z[i, k] = val\n",
    "    M = M_i - (np.dot(np.dot(np.dot(M_i, Z[i,:].T), Z[i,:]), M_i)) / (np.dot(np.dot(Z[i,:], M_i), Z[i,:].T) + 1)\n",
    "    Inv = M\n",
    "    return(Inv)\n",
    "\n",
    "def calcInverse1(Z, M, i, k, val):\n",
    "    # Calculating M_i\n",
    "    part1 = M\n",
    "    part2 = np.dot(M, Z[i,:].T)\n",
    "    part3 = np.dot(part2, Z[i,:])\n",
    "    part4 = np.dot(part3, M)\n",
    "    part5 = np.dot(Z[i,:], M)\n",
    "    part6 = np.dot(part5, Z[i,:].T) - 1\n",
    "\n",
    "    M_i = part1 - part4 / part6\n",
    "\n",
    "    Z[i, k] = val\n",
    "\n",
    "    #Calculating M\n",
    "    part1 = M_i\n",
    "    part2 = np.dot(M_i, Z[i,:].T)\n",
    "    part3 = np.dot(part2, Z[i,:])\n",
    "    part4 = np.dot(part3, M_i)\n",
    "    part5 = np.dot(Z[i,:], M_i)\n",
    "    part6 = np.dot(part5, Z[i,:].T) + 1\n",
    "\n",
    "    M = part1 - part4 / part6\n",
    "\n",
    "    Inv = M\n",
    "    return(Inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood Function \n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define the likelihood function ##\n",
    "# The function returns the log likelihood\n",
    "def likelihood(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    part1 = - (num_objects*(object_dim/2)*np.log(2*np.pi))\n",
    "    part2 = - (num_objects-K_plus)* object_dim *np.log(sigma_X) \n",
    "    part3 = - (object_dim*K_plus)*np.log(sigma_A) \n",
    "    part4 = - (object_dim/2)* np.log(np.dot(np.transpose(Z),Z) + (sigma_X/sigma_A)**2 * np.identity(K_plus))\n",
    "    part5 = (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(np.transpose(X),(np.identity(num_objects) - np.dot(np.dot(Z,M),np.transpose(Z)))),X))\n",
    "    total = part1+part2+part3+part4+part5\n",
    "    return(total)\n",
    "\n",
    "def likelihood1(X, Z, M, sigma_A, sigma_X, K_plus, num_objects, object_dim):\n",
    "    log_ll = -1 * num_objects * object_dim * .5 * np.log(2*np.pi) - 1 * (num_objects - K_plus) * object_dim * np.log(sigma_X) - K_plus * object_dim * np.log(sigma_A) - object_dim * .5 * np.log(np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))) + (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(X.T, np.eye(num_objects) - np.dot(Z, np.dot(M, Z.T))), X))\n",
    "    return(log_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metropolis Functions\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform as unif\n",
    "\n",
    "def met_sigma_A(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, X):\n",
    "    \n",
    "    #Determine M based on sigma_A\n",
    "    #Determine current likelihood based on M and sigma_A\n",
    "    M = Mcalc(Z, K_plus, new_dishes, sigma_X, sigma_A)\n",
    "    l_curr = likelihood1(X, Z[:,0:(K_plus+new_dishes)], M, sigma_A, sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    #sample new value from symmetric distribution close to current value\n",
    "    if unif.rvs(0,1)<0.5:\n",
    "        new_sigma_A = sigma_A - unif.rvs(0,1)/20\n",
    "    else:\n",
    "        new_sigma_A = sigma_A + unif.rvs(0,1)/20\n",
    "    \n",
    "    #Determine M based on new_sigma_A\n",
    "    #Determine current likelihood based on M and new_sigma_A\n",
    "    M = Mcalc(Z, K_plus, new_dishes, sigma_X, new_sigma_A)\n",
    "    l_new = likelihood1(x, Z[:,0:(K_plus+new_dishes)], M, new_sigma_A, sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    acceptance_ratio = np.exp(min(0,l_new - l_curr))\n",
    "    \n",
    "    if unif.rvs(0,1)<acceptance_ratio:\n",
    "        return(new_sigma_A)\n",
    "    else:\n",
    "        return(sigma_A)\n",
    "\n",
    "def met_sigma_X(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, X):\n",
    "    \n",
    "    #Determine M based on sigma_X\n",
    "    #Determine current likelihood based on M and sigma_X\n",
    "    M = Mcalc(Z, K_plus, new_dishes, sigma_X, sigma_A)\n",
    "    l_curr = likelihood1(X, Z[:,0:(K_plus+new_dishes)], M, sigma_A, sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    #sample new value from symmetric distribution close to current value\n",
    "    if unif.rvs(0,1)<0.5:\n",
    "        new_sigma_X = sigma_X - unif.rvs(0,1)/20\n",
    "    else:\n",
    "        new_sigma_X = sigma_X + unif.rvs(0,1)/20\n",
    "    \n",
    "    #Determine M based on new_sigma_A\n",
    "    #Determine current likelihood based on M and new_sigma_A\n",
    "    M = Mcalc(Z, K_plus, new_dishes, new_sigma_X, sigma_A)\n",
    "    l_new = likelihood1(X, Z[:,0:(K_plus+new_dishes)], M, sigma_A, new_sigma_X, K_plus+new_dishes, num_objects, object_dim)\n",
    "    \n",
    "    acceptance_ratio = np.exp(min(0,l_new - l_curr))\n",
    "    \n",
    "    if unif.rvs(0,1)<acceptance_ratio:\n",
    "        return(new_sigma_X)\n",
    "    else:\n",
    "        return(sigma_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mcalc Function\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Mcalc(Z, K_plus, new_dishes, sigma_X, sigma_A):\n",
    "    part1 = np.dot(np.transpose(Z[:,0:(K_plus+new_dishes)]), Z[:,0:(K_plus+new_dishes)])\n",
    "    part2 = (sigma_X/sigma_A)**2 * np.identity(K_plus+new_dishes)\n",
    "    result = np.linalg.inv(part1+part2)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Generation\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvtnorm\n",
    "from scipy.stats import bernoulli\n",
    "import numpy as np\n",
    "\n",
    "### Data Simulation ###\n",
    "\n",
    "## Features/Latent Variables #\n",
    "#Each row of the weight matrix \"W\" specifies one base images(feature/latent variables)\"\n",
    "\n",
    "W = np.array([[0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]])\n",
    "\n",
    "\n",
    "#Each image in our simulated data set is the superposition of four base images#\n",
    "# Number of images/ data points\n",
    "num_objects=100\n",
    "\n",
    "#Dimension of image (6x6)\n",
    "object_dim  = 6*6\n",
    "\n",
    "#Covariance matrix for images/ white noise\n",
    "sigma_x_orig = 0.5\n",
    "I = sigma_x_orig * np.identity(object_dim)\n",
    "\n",
    "#z_i - binary feature matrix (1 x 4) - each entry set to 1 with probability 0.5 and 0 otherwise#\n",
    "#x is data variable - each row correspondes to a superimposed built from a random combination of latent features#\n",
    "#with white noise added - x is built with multivariate gaussian#\n",
    "x = np.zeros((100,36))\n",
    "z = np.zeros((100,4))\n",
    "\n",
    "for i in range(0,num_objects):\n",
    "    z[i,:] = np.array([bernoulli.rvs(p=0.5, size=4)])\n",
    "    x[i,:] = mvtnorm.rvs(np.dot(z[i,:],W), I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sampler\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0 : K_plus is 5 , alpha is 1\n",
      "At iteration 1 : K_plus is 2 , alpha is 0.19793278656564758\n",
      "At iteration 2 : K_plus is 1 , alpha is 0.18112940562137553\n",
      "At iteration 3 : K_plus is 1 , alpha is 0.14496274857982708\n",
      "At iteration 4 : K_plus is 1 , alpha is 0.2368006306966794\n",
      "At iteration 5 : K_plus is 1 , alpha is 0.3449572962159577\n",
      "At iteration 6 : K_plus is 1 , alpha is 0.07060854867152508\n",
      "At iteration 7 : K_plus is 1 , alpha is 0.3436821761995689\n",
      "At iteration 8 : K_plus is 1 , alpha is 0.41505224943183217\n",
      "At iteration 9 : K_plus is 1 , alpha is 0.398484348633701\n",
      "At iteration 10 : K_plus is 1 , alpha is 0.4355980785803627\n",
      "At iteration 11 : K_plus is 1 , alpha is 0.7002155232605516\n",
      "At iteration 12 : K_plus is 1 , alpha is 0.3157221126180234\n",
      "At iteration 13 : K_plus is 1 , alpha is 0.27892101647843054\n",
      "At iteration 14 : K_plus is 1 , alpha is 0.25317873202720154\n",
      "At iteration 15 : K_plus is 1 , alpha is 0.5148855004143401\n",
      "At iteration 16 : K_plus is 1 , alpha is 0.4824878153159636\n",
      "At iteration 17 : K_plus is 1 , alpha is 0.6075676179756484\n",
      "At iteration 18 : K_plus is 1 , alpha is 0.36411097797922926\n",
      "At iteration 19 : K_plus is 1 , alpha is 0.04815822010112294\n",
      "At iteration 20 : K_plus is 1 , alpha is 0.29256774863035606\n",
      "At iteration 21 : K_plus is 1 , alpha is 0.036303569351128294\n",
      "At iteration 22 : K_plus is 1 , alpha is 0.04782032967828843\n",
      "At iteration 23 : K_plus is 1 , alpha is 0.04345101168787738\n",
      "At iteration 24 : K_plus is 1 , alpha is 0.20839972570240708\n",
      "At iteration 25 : K_plus is 1 , alpha is 0.2577180488864511\n",
      "At iteration 26 : K_plus is 1 , alpha is 0.11147423770332289\n",
      "At iteration 27 : K_plus is 1 , alpha is 0.42993877430328975\n",
      "At iteration 28 : K_plus is 1 , alpha is 0.09328847074071214\n",
      "At iteration 29 : K_plus is 1 , alpha is 0.8820871012964892\n",
      "At iteration 30 : K_plus is 1 , alpha is 0.3007468027408383\n",
      "At iteration 31 : K_plus is 1 , alpha is 0.02887218015063562\n",
      "At iteration 32 : K_plus is 1 , alpha is 0.2607335516481265\n",
      "At iteration 33 : K_plus is 1 , alpha is 0.33364834446089336\n",
      "At iteration 34 : K_plus is 1 , alpha is 0.5146024846400343\n",
      "At iteration 35 : K_plus is 1 , alpha is 0.5329908734125542\n",
      "At iteration 36 : K_plus is 1 , alpha is 0.3821751059267444\n",
      "At iteration 37 : K_plus is 1 , alpha is 0.12350522396449955\n",
      "At iteration 38 : K_plus is 1 , alpha is 0.1557687469629782\n",
      "At iteration 39 : K_plus is 1 , alpha is 0.32522243951350344\n",
      "At iteration 40 : K_plus is 1 , alpha is 0.9000545521756074\n",
      "At iteration 41 : K_plus is 1 , alpha is 0.13170828936902357\n",
      "At iteration 42 : K_plus is 1 , alpha is 0.1506291206417438\n",
      "At iteration 43 : K_plus is 1 , alpha is 0.6598863088121271\n",
      "At iteration 44 : K_plus is 1 , alpha is 0.041546971018012135\n",
      "At iteration 45 : K_plus is 1 , alpha is 0.5076757540173661\n",
      "At iteration 46 : K_plus is 1 , alpha is 0.11052697205649306\n",
      "At iteration 47 : K_plus is 1 , alpha is 0.17788937938623817\n",
      "At iteration 48 : K_plus is 1 , alpha is 0.5474576832735359\n",
      "At iteration 49 : K_plus is 1 , alpha is 0.43693007251832455\n",
      "At iteration 50 : K_plus is 1 , alpha is 0.11616464349628922\n",
      "At iteration 51 : K_plus is 1 , alpha is 0.05411582185955411\n",
      "At iteration 52 : K_plus is 1 , alpha is 0.058713818988940285\n",
      "At iteration 53 : K_plus is 1 , alpha is 0.09164036717809879\n",
      "At iteration 54 : K_plus is 1 , alpha is 0.5386567396138671\n",
      "At iteration 55 : K_plus is 1 , alpha is 0.7758851211600386\n",
      "At iteration 56 : K_plus is 1 , alpha is 0.5582726122285012\n",
      "At iteration 57 : K_plus is 1 , alpha is 0.45038035335670934\n",
      "At iteration 58 : K_plus is 1 , alpha is 0.11353062430511418\n",
      "At iteration 59 : K_plus is 1 , alpha is 0.2844295584629385\n",
      "At iteration 60 : K_plus is 1 , alpha is 0.5983630985043271\n",
      "At iteration 61 : K_plus is 1 , alpha is 1.0092037161286103\n",
      "At iteration 62 : K_plus is 1 , alpha is 0.08825033392343423\n",
      "At iteration 63 : K_plus is 1 , alpha is 0.17198527242278863\n",
      "At iteration 64 : K_plus is 1 , alpha is 0.23133087159761392\n",
      "At iteration 65 : K_plus is 1 , alpha is 0.47836620850986994\n",
      "At iteration 66 : K_plus is 1 , alpha is 0.36543024731938556\n",
      "At iteration 67 : K_plus is 1 , alpha is 0.266673160498619\n",
      "At iteration 68 : K_plus is 1 , alpha is 0.16547360517875118\n",
      "At iteration 69 : K_plus is 1 , alpha is 1.1416822776768094\n",
      "At iteration 70 : K_plus is 1 , alpha is 1.2428835706786885\n",
      "At iteration 71 : K_plus is 1 , alpha is 0.4251770174174616\n",
      "At iteration 72 : K_plus is 1 , alpha is 0.12984528983532653\n",
      "At iteration 73 : K_plus is 1 , alpha is 0.32810275457465177\n",
      "At iteration 74 : K_plus is 1 , alpha is 0.5251824031130982\n",
      "At iteration 75 : K_plus is 1 , alpha is 0.11451299888350082\n",
      "At iteration 76 : K_plus is 1 , alpha is 0.27498636395169257\n",
      "At iteration 77 : K_plus is 1 , alpha is 0.5584417116775146\n",
      "At iteration 78 : K_plus is 1 , alpha is 0.22797802388806562\n",
      "At iteration 79 : K_plus is 1 , alpha is 0.4038004019738301\n",
      "At iteration 80 : K_plus is 1 , alpha is 0.08832792807584525\n",
      "At iteration 81 : K_plus is 1 , alpha is 0.7933415087249663\n",
      "At iteration 82 : K_plus is 1 , alpha is 0.46727711144389045\n",
      "At iteration 83 : K_plus is 1 , alpha is 0.7439536393075177\n",
      "At iteration 84 : K_plus is 1 , alpha is 0.12169779145484638\n",
      "At iteration 85 : K_plus is 1 , alpha is 0.22972913671564693\n",
      "At iteration 86 : K_plus is 1 , alpha is 0.33572083732982205\n",
      "At iteration 87 : K_plus is 1 , alpha is 0.09541229487073347\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6d99728b1b48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mk_i\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_plus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msigma_X\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msigma_A\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_plus\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# MINUS ONE TO FIX DIMENSIONALITY MAY BE INCORRECT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Drew\\Anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GENERAL FUNCTION SAMPLER\n",
    "\n",
    "# Harmonic number or N\n",
    "HN = 0\n",
    "for i in range(0, num_objects):\n",
    "    HN = HN + 1/(i+1)\n",
    "\n",
    "E = 100\n",
    "BURN_IN = 0\n",
    "SAMPLE_SIZE = 100\n",
    "\n",
    "# Initializing values for use in our chain\n",
    "sigma_A = 1\n",
    "sigma_X = 1\n",
    "# Poisson rate\n",
    "alpha = 1\n",
    "# Prespecified maximum number of latent features\n",
    "K_inf = 10\n",
    "# Indian Buffet Process Prior\n",
    "Z, K_plus = sampleIBP(alpha, num_objects)\n",
    "# Initialization of our chain for Z\n",
    "chain_Z = np.zeros([SAMPLE_SIZE, num_objects, K_inf])\n",
    "# Initialization of our chain for K\n",
    "chain_K = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for sigma_X\n",
    "chain_sigma_X = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for sigma_A\n",
    "chain_sigma_A = np.zeros([SAMPLE_SIZE, 1])\n",
    "# Initialization of our chain for alpha\n",
    "chain_alpha = np.zeros([SAMPLE_SIZE, 1])\n",
    "\n",
    "# Initializing storage for post burn-in samples\n",
    "s_counter = 0\n",
    "for e in range(0, E):\n",
    "    if(e > BURN_IN):\n",
    "        s_counter = s_counter + 1\n",
    "        chain_Z[s_counter, :, 0:K_plus] = Z[:, 0:K_plus]\n",
    "        chain_K[s_counter] = K_plus\n",
    "        chain_sigma_X[s_counter] = sigma_X\n",
    "        chain_sigma_A[s_counter] = sigma_A\n",
    "        chain_alpha[s_counter] = alpha\n",
    "    print(\"At iteration\", e, \": K_plus is\", K_plus, \", alpha is\", alpha) \n",
    "\n",
    "    for i in range(0, num_objects):\n",
    "        # M matrix will be handy for future computations\n",
    "        # SOMETIMES SINGULAR, NEED TO FIX\n",
    "        M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "        for k in range(0, K_plus):\n",
    "            # Checking to make sure that k < K_plus\n",
    "            if k+1 > K_plus:\n",
    "                break\n",
    "            if Z[i, k] > 0:\n",
    "                # Take care of singularities\n",
    "                if np.sum(Z[:, k]) - Z[i, k] <= 0:\n",
    "                    Z[i, k] = 0\n",
    "                    Z[:, k:(K_plus - 1)] = Z[:, (k+1):K_plus]\n",
    "                    K_plus = K_plus - 1\n",
    "                    M = np.linalg.inv(np.dot(Z[:, 0:K_plus].T, Z[:, 0:K_plus]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus))\n",
    "                    continue\n",
    "             \n",
    "            # This is where he has his calcInverse functions to \n",
    "            # speed up inverse calculations. I just use inverse\n",
    "            # of Z matrix below\n",
    "            M1 = calcInverse(Z[:, 0:K_plus], M, i, k, 1)\n",
    "            M2 = calcInverse(Z[:, 0:K_plus], M, i, k, 0)\n",
    "\n",
    "            # Compute conditional distributions for the current cell in Z\n",
    "            P = []\n",
    "            Z[i, k] = 1\n",
    "            P.append(likelihood1(x, Z[:, 0:K_plus], M1, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(sum(Z[:, k]) - Z[i, k]) - np.log(num_objects))\n",
    "\n",
    "            Z[i, k] = 0\n",
    "            P.append(likelihood1(x, Z[:, 0:K_plus], M2, sigma_A, sigma_X, K_plus, num_objects, object_dim) + np.log(num_objects - sum(Z[:,k])) - np.log(num_objects))\n",
    "            \n",
    "            P = np.exp(P - np.max(P))\n",
    "\n",
    "            # Sample from the conditional\n",
    "            if np.random.uniform() < P[0] / (P[0] + P[1]):\n",
    "                Z[i, k] = 1\n",
    "                M = M1\n",
    "            else:\n",
    "                Z[i, k] = 0\n",
    "                M = M2\n",
    "        \n",
    "        # Sample the number of new dishes for the current object\n",
    "        trun = np.zeros([1, 5])\n",
    "        alpha_N = alpha / num_objects\n",
    "\n",
    "\n",
    "################### ERROR IN DIMENSIONALITY RIGHT HERE ###########################        \n",
    "        for k_i in range(0, 5):\n",
    "            if k_i > 0:\n",
    "                z = np.repeat(0, np.shape(Z)[0])\n",
    "                Z = np.column_stack((Z, z))\n",
    "                Z[i, K_plus:(K_plus+k_i)] = 1\n",
    "            M = np.linalg.inv(np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i)) # MINUS ONE TO FIX DIMENSIONALITY MAY BE INCORRECT\n",
    "            trun[0, k_i] = k_i * np.log(alpha_N) - alpha_N - np.log(np.math.factorial(k_i)) + likelihood1(x, Z[:, 0:(K_plus + k_i)], M, sigma_A, sigma_X, K_plus + k_i, num_objects, object_dim)\n",
    "        Z[i, K_plus:(K_plus+4)] = 0\n",
    "        trun = np.exp(trun - np.max(trun))\n",
    "        trun = trun/np.sum(trun)\n",
    "        p = np.random.uniform()\n",
    "        t = 0\n",
    "        for k_i in range(0,5):\n",
    "            t = trun[0, k_i]\n",
    "            if p < t:\n",
    "                new_dishes = k_i\n",
    "                break\n",
    "        Z[i, K_plus:(K_plus + new_dishes)] = 1\n",
    "        K_plus = K_plus + new_dishes\n",
    "    \n",
    "    # Metropolis steps for sampling sigma_X and sigma_A\n",
    "    sigma_X = met_sigma_X(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, x)\n",
    "\n",
    "    sigma_A = met_sigma_A(Z, K_plus, new_dishes, sigma_X, sigma_A, num_objects, object_dim, x)\n",
    "\n",
    "    # Sample alpha from its conditional posterior\n",
    "    alpha = gamma.rvs(a = 1 + K_plus, scale = 1/(1+HN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))\n",
    "chain_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(Z.T, Z)\n",
    "Z\n",
    "k_i\n",
    "i\n",
    "np.eye(K_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = x\n",
    "Z = Z[:, 0:(K_plus + k_i)]\n",
    "K_plus = K_plus + k_i\n",
    "\n",
    "-1 * num_objects * object_dim * .5 * np.log(2*np.pi) - 1 * (num_objects - K_plus) * object_dim * np.log(sigma_X) - K_plus * object_dim * np.log(sigma_A) - object_dim * .5 * np.log(np.linalg.det((np.dot(Z.T, Z) + (sigma_X**2/sigma_A**2)*np.eye(K_plus)))) + (-1/(2*sigma_X**2)) * np.trace(np.dot(np.dot(X.T, np.eye(num_objects) - np.dot(Z, np.dot(M, Z.T))), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k_i in range(0, 5):\n",
    "            Z[i, K_plus:(K_plus+k_i)] = 1\n",
    "            M = np.linalg.inv(np.dot(Z[:, 0:(K_plus + k_i)].T, Z[:, 0:(K_plus+k_i)]) + (sigma_X**2/sigma_A**2) * np.eye(K_plus + k_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = np.zeros([1, 5])\n",
    "f[0, 1] = 10\n",
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
